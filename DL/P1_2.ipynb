{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.10.15\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TensorFlow and Keras 2.15.0\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Flatten, Dense)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Suppress TensorFlow warnings (optional)\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-021\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-021/Epochs_sub-021.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-026\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-019\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-026/Epochs_sub-026.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-019/Epochs_sub-019.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-010\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-017\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-010/Epochs_sub-010.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-017/Epochs_sub-017.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-028\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-016\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-029\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-028/Epochs_sub-028.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-016/Epochs_sub-016.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-029/Epochs_sub-029.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-011\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-027\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-011/Epochs_sub-011.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-027/Epochs_sub-027.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-018\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-020\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-018/Epochs_sub-018.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-020/Epochs_sub-020.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-002\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-002/Epochs_sub-002.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-005/Epochs_sub-005.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-033\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-034\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-033/Epochs_sub-033.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-034/Epochs_sub-034.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-035\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-032\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-035/Epochs_sub-035.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-032/Epochs_sub-032.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-004/Epochs_sub-004.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-003\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-003/Epochs_sub-003.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-040/Epochs_sub-040.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-025\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-022\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-025/Epochs_sub-025.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-022/Epochs_sub-022.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-014\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-014/Epochs_sub-014.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-013/Epochs_sub-013.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-012\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-015\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-012/Epochs_sub-012.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-015/Epochs_sub-015.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-023\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-024\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-023/Epochs_sub-023.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-024/Epochs_sub-024.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-039\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-039/Epochs_sub-039.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-006/Epochs_sub-006.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-001\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-008\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-001/Epochs_sub-001.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-008/Epochs_sub-008.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-037/Epochs_sub-037.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-030\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-031\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-030/Epochs_sub-030.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-031/Epochs_sub-031.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-009\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-036\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-009/Epochs_sub-009.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-036/Epochs_sub-036.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Loading the processed data: sub-038\n",
      "\n",
      "\n",
      "***** Loading the processed data: sub-007\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-038/Epochs_sub-038.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
      "/var/folders/dh/551p960n6mv9t9byzj8pp0640000gp/T/ipykernel_4708/3738345600.py:34: RuntimeWarning: This filename (/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed/sub-007/Epochs_sub-007.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "# Define the data directory where subject folders are located\n",
    "data_dir = '/Users/BAEK/Code/neurEx/data/N170/Data_Preprocessed'\n",
    "\n",
    "# List all subject folders\n",
    "subject_folders = [sub for sub in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, sub))]\n",
    "'''\n",
    "subjects = []\n",
    "for sub in os.listdir(data_dir):\n",
    "    if os.path.isdir(os.path.join(data_dir, sub)):\n",
    "        subjects.append(sub)\n",
    "'''\n",
    "\n",
    "# Initialize lists to hold data and labels from all subjects\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Loop over each subject folder\n",
    "for subject in subject_folders:\n",
    "    \n",
    "    subject_data_dir = os.path.join(data_dir, subject)\n",
    "    \n",
    "    # Construct file paths for the subject's data\n",
    "    X_file = os.path.join(subject_data_dir, f'Epochs_{subject}.fif')\n",
    "    \n",
    "    # Check if data files exist\n",
    "    if os.path.exists(X_file):\n",
    "        \n",
    "        print()\n",
    "        print(f'***** Loading the processed data: {subject}')\n",
    "        print()\n",
    "        \n",
    "        # Load the data\n",
    "        X_subject = mne.read_epochs(X_file, preload=True, verbose=False)\n",
    "        y_subject = X_subject.events[:, 2]\n",
    "        \n",
    "        # Append to the list\n",
    "        X_sub_data = X_subject.get_data()\n",
    "        X_list.append(X_sub_data)\n",
    "        y_list.append(y_subject)\n",
    "        \n",
    "    else:\n",
    "        print()\n",
    "        print(f'***** Data file Does Not Exist: {subject}')\n",
    "        print()\n",
    "\n",
    "# Ensure that at least one subject has been loaded\n",
    "if len(X_list) == 0:\n",
    "    print()\n",
    "    raise ValueError(\"No data was loaded. Please check your data directory and files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P8 (Right Parietal): \n",
    "\n",
    "The parietal lobe is involved in sensory processing and the integration of sensory information. Specifically, the right parietal region is important for spatial awareness, visual processing, and attention. It is often engaged in tasks related to visual perception and sensory-motor coordination.\n",
    "\n",
    "### PO8 (Right Parieto-Occipital): \n",
    "\n",
    "The occipital lobe is the primary visual processing center in the brain, and the parietal lobe integrates sensory information. The PO8 region is crucial for processing visual information from both the environment and sensory input. It is especially important in the recognition of objects, including faces, and is involved in spatial processing and attention to visual stimuli.\n",
    "\n",
    "### O2 (Right Occipital): \n",
    "\n",
    "The occipital lobe is the brain’s main area for visual processing, including perception of visual stimuli such as shapes, colors, and faces. The right occipital lobe is particularly active during tasks related to visual processing and recognition of visual patterns.\n",
    "\n",
    "### P10 (Right Parietal-Temporal): \n",
    "\n",
    "The parietal lobe is involved in sensory integration, spatial awareness, and attention, while the temporal lobe is important for processing sensory input, especially auditory and visual information. The temporal lobe is heavily involved in memory, recognition, and face processing.\n",
    "\n",
    "\n",
    "        a = np.array([[1, 2], \n",
    "                    [3, 4]])\n",
    "        b = np.array([[5, 6], \n",
    "                    [7, 8]])\n",
    "\n",
    "        np.concatenate((a, b), axis=0)\n",
    "        # [[1, 2],\n",
    "        #  [3, 4],\n",
    "        #  [5, 6],\n",
    "        #  [7, 8]]\n",
    "\n",
    "        np.vstack((a,b))\n",
    "        # [[1, 2],\n",
    "        #  [3, 4],\n",
    "        #  [5, 6],\n",
    "        #  [7, 8]]\n",
    "\n",
    "        np.concatenate((a, b), axis=1)\n",
    "        # [[1 2 5 6]\n",
    "        #  [3 4 7 8]]\n",
    "\n",
    "        a = np.array([[[1, 2], \n",
    "                    [3, 4]]])  # Shape: (1, 2, 2)\n",
    "\n",
    "        b = np.array([[[5, 6], \n",
    "                    [7, 8]]])  # Shape: (1, 2, 2)\n",
    "\n",
    "        np.concatenate((a, b), axis=2)\n",
    "        # [[[1, 2, 5, 6],\n",
    "        #   [3, 4, 7, 8]]]\n",
    "\n",
    "        np.vstack((a,b))\n",
    "        # [[[1, 2],\n",
    "        #   [3, 4]],\n",
    "        #\n",
    "        #   [[5, 6],\n",
    "        #    [7, 8]]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Mock EEG data with shape (3 samples, 4 channels, 5 timepoints)\n",
    "        X = np.array([\n",
    "            [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20]],\n",
    "            [[21, 22, 23, 24, 25], [26, 27, 28, 29, 30], [31, 32, 33, 34, 35], [36, 37, 38, 39, 40]],\n",
    "            [[41, 42, 43, 44, 45], [46, 47, 48, 49, 50], [51, 52, 53, 54, 55], [56, 57, 58, 59, 60]]\n",
    "        ])\n",
    "        # Shape: (3 samples, 4 channels, 5 timepoints)\n",
    "\n",
    "        chan_idx = [1, 3]  # Select only channels 1 and 3\n",
    "\n",
    "        X = X[:, chan_idx, :]\n",
    "\n",
    "        # Extracts only the specified channels\n",
    "        X = np.array([\n",
    "            [[6, 7, 8, 9, 10], [16, 17, 18, 19, 20]],\n",
    "            [[26, 27, 28, 29, 30], [36, 37, 38, 39, 40]],\n",
    "            [[46, 47, 48, 49, 50], [56, 57, 58, 59, 60]]\n",
    "        ])\n",
    "        # Shape: (3 samples, 2 channels, 5 timepoints)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Labels for three subjects\n",
    "        y_list = [\n",
    "            np.array([0, 1, 0, 1]),  # Subject 1\n",
    "            np.array([1, 1, 0, 0]),  # Subject 2\n",
    "            np.array([0, 0, 1, 1])   # Subject 3\n",
    "        ]\n",
    "\n",
    "        np.concatenate(y_list, axis=0)\n",
    "        #[0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1])  # Shape: (12,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape before filtering: X=(23602, 4, 820), y=(23602,)\n",
      "Combined data shape after filtering: X=(6104, 4, 102), y=(6104,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.65535473e-07, -2.33084976e-07, -2.56221681e-07, -3.35722922e-07,\n",
       "       -4.71088408e-07, -6.60497783e-07, -9.00880692e-07, -1.18786204e-06,\n",
       "       -1.51586949e-06, -1.87812459e-06, -2.26676702e-06, -2.67311763e-06,\n",
       "       -3.08767533e-06, -3.50033306e-06, -3.90088247e-06, -4.27891778e-06,\n",
       "       -4.62421035e-06, -4.92699383e-06, -5.17809914e-06, -5.36951111e-06,\n",
       "       -5.49421166e-06, -5.54619740e-06, -5.52102088e-06, -5.41581248e-06,\n",
       "       -5.22933673e-06, -4.96202801e-06, -4.61585473e-06, -4.19435119e-06,\n",
       "       -3.70253657e-06, -3.14671301e-06, -2.53441977e-06, -1.87421798e-06,\n",
       "       -1.17549646e-06, -4.48325484e-07,  2.96874105e-07,  1.04961514e-06,\n",
       "        1.79936683e-06,  2.53584337e-06,  3.24924111e-06,  3.93041848e-06,\n",
       "        4.57091855e-06,  5.16319560e-06,  5.70080136e-06,  6.17847393e-06,\n",
       "        6.59201477e-06,  6.93824957e-06,  7.21520756e-06,  7.42191790e-06,\n",
       "        7.55842064e-06,  7.62581203e-06,  7.62584541e-06,  7.56124113e-06,\n",
       "        7.43529985e-06,  7.25198172e-06,  7.01556442e-06,  6.73096894e-06,\n",
       "        6.40343235e-06,  6.03826998e-06,  5.64088057e-06,  5.21691702e-06,\n",
       "        4.77197837e-06,  4.31159448e-06,  3.84124278e-06,  3.36638641e-06,\n",
       "        2.89221906e-06,  2.42390560e-06,  1.96652901e-06,  1.52481222e-06,\n",
       "        1.10321057e-06,  7.05951629e-07,  3.36879789e-07, -5.09837175e-10,\n",
       "       -3.03096621e-07, -5.68101464e-07, -7.93489514e-07, -9.77722762e-07,\n",
       "       -1.11973417e-06, -1.21901905e-06, -1.27566862e-06, -1.29047739e-06,\n",
       "       -1.26481735e-06, -1.20055294e-06, -1.10021996e-06, -9.66808793e-07,\n",
       "       -8.03887902e-07, -6.15385769e-07, -4.05521183e-07, -1.79039269e-07,\n",
       "        5.93880190e-08,  3.05053800e-07,  5.53013145e-07,  7.98585830e-07,\n",
       "        1.03721082e-06,  1.26473081e-06,  1.47720015e-06,  1.67114651e-06,\n",
       "        1.84364616e-06,  1.99222230e-06,  2.11499428e-06,  2.21065354e-06,\n",
       "        2.27832317e-06,  2.31764697e-06])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get channel names from the last loaded subject\n",
    "# This retrieves the names of the channels from the EEG data. These names represent the locations or positions of the EEG electrodes on the scalp, like ‘FP1’, ‘F3’, ‘P3’, etc.\n",
    "channels = X_subject.ch_names\n",
    "\n",
    "# Channels such as P8, PO8, O2, and P10 are situated over or near these regions in the parietal and occipital lobes, which are strongly involved in facial processing and visual stimuli processing.\n",
    "# Studies on the N170 often report that the most reliable and strongest N170 signals are found in right-lateralized occipital-temporal regions. \n",
    "coi = ['P8', 'PO8', 'O2', 'P10']\n",
    "\n",
    "# Creates a list of indices (chan_idx) for the channels of interest. \n",
    "# It finds the index (position) of each channel in the coi list from the full channels list.\n",
    "chan_idx = [channels.index(chan) for chan in coi] # [25, 27, 29, 26]\n",
    "'''\n",
    "chan_idx = []\n",
    "for chan in coi:\n",
    "    index = channels.index(chan)    # Get the index of the channel in the full list\n",
    "    chan_idx.append(index)          # Append the index to the list\n",
    "'''\n",
    "\n",
    "### Concatenate data from all subjects\n",
    "# X_list: This is a list containing the EEG data arrays for multiple subjects. Each array in X_list typically has a shape like (trials, channels, time_points).\n",
    "\n",
    "# NumPy arrays are multi-dimensional, and each dimension is associated with an axis:\n",
    "# 0 represents the rows (vertical direction).\n",
    "# 1 represents the columns (horizontal direction).\n",
    "# 2, 3, and beyond represent additional dimensions (for higher-dimensional arrays).\n",
    "\n",
    "# Combines the EEG data for all subjects along the trials dimension. Same as X = np.vstack(X_list) when concatenate(X_list, axis = 0)\n",
    "# After concatenation, X will contain all trials from all subjects in a single array.\n",
    "# If, for example, each subject’s data has 100 trials, and there are 10 subjects, then X will have a shape (1000, channels, time_points).\n",
    "X = np.concatenate(X_list, axis = 0) # will combine all x of X(x,y,z)\n",
    "\n",
    "# A slicing operation on the X array, and it extracts specific subsets of the data along its second axis (dimensions).\n",
    "X = X[:, chan_idx, :]  # will change the y of X(x,y,z)\n",
    "\n",
    "# Combines all the individual y arrays in y_list into a single, larger 1D or 2D array along the first axis (axis=0)\n",
    "y = np.concatenate(y_list, axis = 0)\n",
    "\n",
    "print(f'Combined data shape before filtering: X={X.shape}, y={y.shape}')\n",
    "\n",
    "### Filter stimulus events\n",
    "stimulus_labels = [1, 2]  # 1: Face, 2: Car\n",
    "# Checks each element in y to see if it is in the stimulus_labels list.\n",
    "# Returns a boolean array (stimulus_mask) of the same length as y.\n",
    "stimulus_mask = np.isin(y, stimulus_labels)\n",
    "X = X[stimulus_mask] # will change the x of X(x,y,z)\n",
    "y = y[stimulus_mask]\n",
    "\n",
    "# Adjust labels to start from 0\n",
    "y = y - 1\n",
    "\n",
    "# Focus on the N170 response by selecting data around 170 ms \n",
    "# Selecting Data Around the N170 Response (time window selection)\n",
    "# This defines the time window you’re interested in, i.e., 100ms to 200ms after the stimulus.\n",
    "# This means you are interested in data collected from 0.1 seconds to 0.2 seconds after the stimulus\n",
    "tmin, tmax = 0.10, 0.2   # 100 ms to 200 ms\n",
    "times = X_subject.times  # Time vector from the epochs\n",
    "# Filter the times so that only the times that lies between tmin and tmax stay\n",
    "time_mask = (times >= tmin) & (times <= tmax)\n",
    "X_focused = X[:, :, time_mask]\n",
    "\n",
    "print(f'Combined data shape after filtering: X={X_focused.shape}, y={y.shape}')\n",
    "\n",
    "X_focused[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6104, 4, 102)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-2.65535473e-07, -2.33084976e-07, -2.56221681e-07, ...,\n",
       "          2.21065354e-06,  2.27832317e-06,  2.31764697e-06],\n",
       "        [ 1.52646923e-06,  1.55423677e-06,  1.55282390e-06, ...,\n",
       "          7.41099594e-07,  9.07904801e-07,  1.05732774e-06],\n",
       "        [-7.22147654e-06, -7.38670919e-06, -7.53458689e-06, ...,\n",
       "         -4.07241284e-07, -2.46243744e-07, -8.30428524e-08],\n",
       "        [ 5.03884314e-06,  5.25305508e-06,  5.36733101e-06, ...,\n",
       "          8.15229414e-06,  8.16074655e-06,  8.08678148e-06]],\n",
       "\n",
       "       [[-1.47737646e-06, -1.67229044e-06, -1.82316827e-06, ...,\n",
       "          3.79423474e-06,  3.87306189e-06,  3.89641451e-06],\n",
       "        [-6.68424724e-07, -6.97640298e-07, -7.08379923e-07, ...,\n",
       "         -1.09889269e-06, -8.65716336e-07, -6.51313899e-07],\n",
       "        [-7.48422084e-07, -9.07281396e-07, -1.03889632e-06, ...,\n",
       "         -8.53871045e-07, -6.54174386e-07, -4.62437718e-07],\n",
       "        [-4.21238231e-06, -4.83159445e-06, -5.40723513e-06, ...,\n",
       "         -1.00315418e-08,  2.54398673e-07,  5.16855537e-07]],\n",
       "\n",
       "       [[-1.58109676e-06, -1.59698379e-06, -1.62114536e-06, ...,\n",
       "          9.26621018e-07,  8.29454003e-07,  7.13630019e-07],\n",
       "        [-4.45750903e-06, -4.44266032e-06, -4.42975663e-06, ...,\n",
       "          2.08250570e-06,  2.06292653e-06,  2.02929306e-06],\n",
       "        [-7.26043127e-06, -7.20383261e-06, -7.18244503e-06, ...,\n",
       "         -4.33158683e-06, -4.11023377e-06, -3.90746092e-06],\n",
       "        [ 2.11854290e-06,  1.82837104e-06,  1.53560948e-06, ...,\n",
       "         -2.51281231e-07, -6.76515637e-07, -1.08717251e-06]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.41856908e-06, -2.79457211e-06, -3.19109940e-06, ...,\n",
       "         -2.42563176e-06, -2.00228238e-06, -1.71271193e-06],\n",
       "        [-6.96223853e-07, -6.26056312e-07, -4.53751146e-07, ...,\n",
       "          5.96395443e-06,  6.74311493e-06,  7.50302313e-06],\n",
       "        [ 3.95886778e-07,  4.29583042e-07,  5.65602897e-07, ...,\n",
       "          5.21327113e-06,  5.82447718e-06,  6.48118637e-06],\n",
       "        [ 1.04313421e-06,  8.32708297e-07,  5.80027221e-07, ...,\n",
       "          8.27353857e-06,  8.85092542e-06,  9.35755155e-06]],\n",
       "\n",
       "       [[ 2.70915841e-06,  3.19704007e-06,  3.67138456e-06, ...,\n",
       "          2.98408722e-06,  2.79047846e-06,  2.55993509e-06],\n",
       "        [ 7.13312815e-06,  7.51920269e-06,  7.85860489e-06, ...,\n",
       "          3.97416948e-06,  4.26586150e-06,  4.53748416e-06],\n",
       "        [ 1.17926740e-05,  1.24428749e-05,  1.30259113e-05, ...,\n",
       "          1.09956960e-05,  1.13510370e-05,  1.16468868e-05],\n",
       "        [ 1.89418709e-06,  2.10378980e-06,  2.27546334e-06, ...,\n",
       "          7.46997593e-07,  8.92711339e-07,  1.05645668e-06]],\n",
       "\n",
       "       [[ 3.04348611e-06,  2.54423522e-06,  1.99804985e-06, ...,\n",
       "         -7.77291475e-07, -1.00802660e-06, -1.27954244e-06],\n",
       "        [ 7.12797640e-06,  7.01452778e-06,  6.88476227e-06, ...,\n",
       "          1.06899452e-05,  1.06339998e-05,  1.05105028e-05],\n",
       "        [ 8.32707117e-06,  8.15730665e-06,  7.90702293e-06, ...,\n",
       "          9.06495855e-06,  8.92041776e-06,  8.70979688e-06],\n",
       "        [ 5.80448149e-06,  5.73677491e-06,  5.66561602e-06, ...,\n",
       "          9.76266858e-06,  9.35750959e-06,  8.83536909e-06]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_focused.shape)\n",
    "\n",
    "X_focused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. X\n",
    "\n",
    "NumPy arrays are multidimensional data structures. Each dimension corresponds to a different aspect of the data.\n",
    "\n",
    "First Dimension (595):\n",
    "•\tRepresents 595 epochs (or trials) in your experiment. Each epoch corresponds to a single trial where the EEG data is collected during a stimulus presentation or event.\n",
    "\t•\tThis dimension will vary as you add more subjects or trials, but each epoch will contain data in the format specified by the next two dimensions.\n",
    "\n",
    "Second Dimension (33):\n",
    "•\tRepresents 33 EEG channels (electrodes) capturing data from various scalp locations. Each channel corresponds to a different electrode that records electrical activity from the brain.\n",
    "•\tThese 33 channels provide spatial information about where the brain activity is occurring on the scalp.\n",
    "•\tThis dimension will remain the same across all subjects, as you are using the same number of electrodes to capture the data.\n",
    "\n",
    "Third Dimension (820):\n",
    "•\tRepresents 820 time points for each epoch. These are the EEG values recorded over time during each trial. The EEG signal is continuous, and the time points correspond to the sampling rate and the duration of the recording.\n",
    "•\tThis dimension also remains the same across all subjects, as the data is sampled at the same rate and duration for each trial.\n",
    "\n",
    "2. For example \n",
    "\n",
    "import numpy as np\n",
    "box = np.random.rand(10, 20, 5)  # Generate random values in a (10, 20, 5) shape\n",
    "print(box)\n",
    "\n",
    "  array([[[0.72, 0.43, 0.99, 0.58, 0.16],  # Epoch 1, Channel 1\n",
    "          [0.63, 0.34, 0.88, 0.44, 0.01],  # Epoch 1, Channel 2\n",
    "          ...\n",
    "          [0.56, 0.11, 0.98, 0.75, 0.22]], # Epoch 1, Channel 20\n",
    "         [[0.89, 0.22, 0.78, 0.33, 0.55],  # Epoch 2, Channel 1\n",
    "          [0.71, 0.48, 0.64, 0.88, 0.19],\n",
    "          ...\n",
    "          [0.12, 0.95, 0.72, 0.66, 0.23]], # Epoch 2, Channel 20\n",
    "          ...\n",
    "         [[0.82, 0.73, 0.61, 0.88, 0.34],  # Epoch 10, Channel 1\n",
    "          [0.44, 0.56, 0.77, 0.93, 0.18],\n",
    "          ...\n",
    "          [0.62, 0.29, 0.38, 0.99, 0.41]]  # Epoch 10, Channel 20\n",
    "        ])\n",
    "\n",
    "Step 1: Mapping xx to Excel Files\n",
    "\n",
    "The structure of your EEG data (xx) can be thought of as:\n",
    "\t•\tRows in the Excel sheet (y-axis): These correspond to the 33 EEG channels.\n",
    "\t•\tColumns in the Excel sheet (x-axis): These correspond to the 820 time points.\n",
    "\t•\tMultiple Excel sheets (z-axis): Each sheet corresponds to one epoch (595 epochs total).\n",
    "\n",
    "Imagine one epoch of data as a single Excel file. For Epoch 1, you have a 33×820 table:\n",
    "\n",
    "Channel/Time\t t1\t    t2\t t3\t  …\tt820\n",
    "         Ch1\t0.12\t-0.34\t0.56\t…\t0.44\n",
    "         Ch2\t0.15\t-0.23\t0.54\t…\t0.39\n",
    "         Ch3\t0.10\t-0.18\t0.45\t…\t0.35\n",
    "          …\t   …\t    …\t   …\t  …\t …\n",
    "         Ch33\t0.22\t-0.28\t0.67\t…\t0.50\n",
    "\n",
    "Step 3: Visualizing Across Epochs\n",
    "\n",
    "Now, you stack 595 Excel files one on top of the other. Each file has the same dimensions (33×820), but the data values inside them differ because each epoch captures a slightly different response (depending on the stimulus, noise, or other factors).\n",
    "\n",
    "Step 4: Linking to the Labels (yy)\n",
    "\n",
    "Each Excel file (epoch) corresponds to a single value in yy, which indicates the event type or condition. For example:\n",
    "\n",
    "Epoch\tLabel (Event Type)\n",
    "  1\t    1   (Face stimulus)\n",
    "  2\t    2   (Car stimulus)\n",
    "  3    \t1   (Face stimulus)\n",
    "  …\t    …       …\n",
    " 595   \t4   (Scrambled car)\n",
    "\n",
    "Step 5: Overall Data Structure\n",
    "\n",
    "Think of your data as 595 Excel files:\n",
    "•\tEach file has 33 rows (EEG channels) and 820 columns (time points).\n",
    "•\tYou also have a separate label file (yy) that tells you what condition or event type corresponds to each Excel file.\n",
    "•\tFor the table we created for epoch 1 with a 33×820 table, it's name is 1 (Face stimulus) according to yy.\n",
    "•\tx (first dimension): Epochs (each epoch is like a “table”).\n",
    "•\ty (second dimension): Channels (columns in the table).\n",
    "•\tz (third dimension): Time points (rows in the table).\n",
    "\n",
    "3. Normalization (Z-score normalization)\n",
    "\n",
    "Normalization is a standard pre-processing step in machine learning and signal processing to ensure that all features (in this case, the EEG signal values across all epochs) are on the same scale. Without normalization, features with larger scales (like EEG channels with higher amplitude signals) might dominate over features with smaller scales (like signals with less variance). This can make the training of machine learning models less effective.\n",
    "\n",
    "Z-score Normalization is a type of standardization, where we scale the data such that it has a mean of 0 and a standard deviation of 1. \n",
    "\n",
    "Z = \\frac{X - \\mu}{\\sigma}\n",
    "\n",
    "Where:\n",
    "•\tX is the original data point (EEG signal value at a specific time and channel),\n",
    "•\t\\mu is the mean of the data (average signal value),\n",
    "•\t\\sigma is the standard deviation (how much the data varies from the mean).\n",
    "\n",
    "This normalization ensures that the data has a consistent scale, which helps improve the performance of machine learning algorithms, especially deep learning models.\n",
    "\n",
    "4. For example \n",
    "\n",
    "x = [\n",
    "    [1, 2, 3, 4],  # Epoch 1\n",
    "    [5, 6, 7, 8],  # Epoch 2\n",
    "    [9, 10, 11, 12] # Epoch 3\n",
    "]\n",
    "\n",
    "Here, each row corresponds to an epoch (a trial), and each column corresponds to a feature (in this case, 4 features).\n",
    "\t•\tEpoch 1: [1, 2, 3, 4]\n",
    "\t•\tEpoch 2: [5, 6, 7, 8]\n",
    "\t•\tEpoch 3: [9, 10, 11, 12]\n",
    "\n",
    "Step-by-Step Z-Score Normalization\n",
    "\n",
    "\n",
    "Mean and Standard Deviation Calculation:\n",
    "For each feature (column), we calculate the mean and standard deviation:\n",
    "\t\n",
    "  •\tMean of Feature 1:  \\frac{1 + 5 + 9}{3} = 5 \n",
    "\t•\tMean of Feature 2:  \\frac{2 + 6 + 10}{3} = 6 \n",
    "\t•\tMean of Feature 3:  \\frac{3 + 7 + 11}{3} = 7 \n",
    "\t•\tMean of Feature 4:  \\frac{4 + 8 + 12}{3} = 8 \n",
    "\t\n",
    "  •\tStandard Deviation of Feature 1:\n",
    " \\sqrt{\\frac{(1-5)^2 + (5-5)^2 + (9-5)^2}{3}} = 3.464 \n",
    "\t•\tStandard Deviation of Feature 2:\n",
    " \\sqrt{\\frac{(2-6)^2 + (6-6)^2 + (10-6)^2}{3}} = 3.464 \n",
    "\t•\tStandard Deviation of Feature 3:\n",
    " \\sqrt{\\frac{(3-7)^2 + (7-7)^2 + (11-7)^2}{3}} = 3.464 \n",
    "\t•\tStandard Deviation of Feature 4:\n",
    " \\sqrt{\\frac{(4-8)^2 + (8-8)^2 + (12-8)^2}{3}} = 3.464 \n",
    "\n",
    "Apply Z-Score Normalization:\n",
    "\n",
    "Z-score normalization is applied by the formula:\n",
    "\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "\n",
    "where:\n",
    "\t•\t x  is the original value,\n",
    "\t•\t \\mu  is the mean of the feature,\n",
    "\t•\t \\sigma  is the standard deviation of the feature.\n",
    "For Epoch 1, applying Z-score to each feature:\n",
    "\t•\tFeature 1:  \\frac{1 - 5}{3.464} = -1.155 \n",
    "\t•\tFeature 2:  \\frac{2 - 6}{3.464} = -1.155 \n",
    "\t•\tFeature 3:  \\frac{3 - 7}{3.464} = -1.155 \n",
    "\t•\tFeature 4:  \\frac{4 - 8}{3.464} = -1.155 \n",
    "Normalized Epoch 1: [-1.155, -1.155, -1.155, -1.155]\n",
    "\n",
    "Similarly, apply the Z-score normalization for Epoch 2 and Epoch 3:\n",
    "\n",
    "Normalized Epoch 2:\n",
    "\t•\tFeature 1:  \\frac{5 - 5}{3.464} = 0 \n",
    "\t•\tFeature 2:  \\frac{6 - 6}{3.464} = 0 \n",
    "\t•\tFeature 3:  \\frac{7 - 7}{3.464} = 0 \n",
    "\t•\tFeature 4:  \\frac{8 - 8}{3.464} = 0 \n",
    "Normalized Epoch 2: [0, 0, 0, 0]\n",
    "\n",
    "Normalized Epoch 3:\n",
    "\t•\tFeature 1:  \\frac{9 - 5}{3.464} = 1.155 \n",
    "\t•\tFeature 2:  \\frac{10 - 6}{3.464} = 1.155 \n",
    "\t•\tFeature 3:  \\frac{11 - 7}{3.464} = 1.155 \n",
    "\t•\tFeature 4:  \\frac{12 - 8}{3.464} = 1.155 \n",
    "Normalized Epoch 3: [1.155, 1.155, 1.155, 1.155]\n",
    "\n",
    "x = [\n",
    "    [-1.155, -1.155, -1.155, -1.155],  # Epoch 1\n",
    "    [0,     0,     0,     0    ],     # Epoch 2\n",
    "    [1.155, 1.155, 1.155, 1.155]      # Epoch 3\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBefore the np.newaxis operation:\\n•\\tThe shape of your array X_normalized is something like (samples, channels, time_points).\\n•\\tThe data is structured in a 3D array with samples as the first dimension, channels as the second dimension, and time points as the third dimension.\\n•\\tEach time point for every channel in every sample is a scalar value (real number), and the array looks like this:\\n array([[[ 3.24529244e-01,  4.11996053e-01,  4.91609174e-01, ...],\\n        [ 1.84049422e-01,  2.35332724e-01,  2.83798373e-01, ...],\\n        [-2.38773378e-01, -2.04526201e-01, -1.74333753e-01, ...],\\n        [ 4.25627014e-01,  4.73232880e-01,  5.16544162e-01, ...]],\\n\\n       [[-2.96749702e-01, -2.86137936e-01, -2.64685230e-01, ...],\\n        [-4.21221455e-01, -4.03617815e-01, -3.79205829e-01, ...],\\n        [ 2.98252681e-01,  2.99339691e-01,  3.04971293e-01, ...],\\n        [-2.24049276e-02, -2.27949784e-02, -2.29925722e-02, ...]],\\n\\n       [[-4.12923850e-01, -3.98015639e-01, -3.82177900e-01, ...], \\n       ...\\n\\nAfter the np.newaxis operation:\\n•\\tThe shape changes to (samples, channels, time_points, 1).\\n•\\tThis operation wraps each individual value (the scalar for each time point) into its own array (of size 1) and adds a new dimension.\\n•\\tNow, each time point for each channel/sample is a 1D array (each value in your array is now encapsulated as a single-element list or array).\\narray([[[[ 3.24529244e-01],\\n         [ 4.11996053e-01],\\n         [ 4.91609174e-01],\\n         ...],\\n \\n        [[ 1.84049422e-01],\\n         [ 2.35332724e-01],\\n         [ 2.83798373e-01],\\n         ...],\\n\\n        [[-2.38773378e-01],\\n         [-2.04526201e-01],\\n         [-1.74333753e-01],\\n         ...],\\n\\n        [[ 4.25627014e-01],\\n         [ 4.73232880e-01],\\n         [ 5.16544162e-01],\\n         ...]]], \\n       ...\\n'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize data per channel (not global)\n",
    "def normalize_per_channel(X_data):\n",
    "    # Creates an array of the same shape as X_data, but with all values initialized to zero. \n",
    "    # The purpose of this array is to store the normalized data.\n",
    "    X_norm = np.zeros_like(X_data)\n",
    "    for i in range(X_data.shape[1]):  # Loop over the range channels: total 4 times from i=0 to i=3\n",
    "        scaler = StandardScaler()\n",
    "        # X_channel will have a shape of (6104, 61), representing the data for all trials across all time points for channel i\n",
    "        # X_data = [[[a1], [a2], [a3], [a4]], \n",
    "        #           [[b1], [b2], [b3], [b4]], \n",
    "        #           [[c1], [c2], [c3], [c4]]]\n",
    "        # X_channel = [[a1],[b1],[c1]]\n",
    "        X_channel = X_data[:, i, :]\n",
    "        # First, it computes the mean and standard deviation for each feature (each column) in X_channel. \n",
    "        # After calculating the mean and standard deviation, it transforms the data by subtracting the mean and dividing by the standard deviation\n",
    "        X_norm[:, i, :] = scaler.fit_transform(X_channel)\n",
    "    return X_norm\n",
    "\n",
    "X_normalized = normalize_per_channel(X_focused)\n",
    "\n",
    "# Reshape data for Conv2D (samples, channels, times, depth/feature)\n",
    "X = X_normalized[..., np.newaxis]  # Shape: (samples, channels, times, 1)\n",
    "\n",
    "'''\n",
    "Before the np.newaxis operation:\n",
    "•\tThe shape of your array X_normalized is something like (samples, channels, time_points).\n",
    "•\tThe data is structured in a 3D array with samples as the first dimension, channels as the second dimension, and time points as the third dimension.\n",
    "•\tEach time point for every channel in every sample is a scalar value (real number), and the array looks like this:\n",
    " array([[[ 3.24529244e-01,  4.11996053e-01,  4.91609174e-01, ...],\n",
    "         [ 1.84049422e-01,  2.35332724e-01,  2.83798373e-01, ...],\n",
    "         [-2.38773378e-01, -2.04526201e-01, -1.74333753e-01, ...],\n",
    "         [ 4.25627014e-01,  4.73232880e-01,  5.16544162e-01, ...]],\n",
    "\n",
    "        [[-2.96749702e-01, -2.86137936e-01, -2.64685230e-01, ...],\n",
    "         [-4.21221455e-01, -4.03617815e-01, -3.79205829e-01, ...],\n",
    "         [ 2.98252681e-01,  2.99339691e-01,  3.04971293e-01, ...],\n",
    "         [-2.24049276e-02, -2.27949784e-02, -2.29925722e-02, ...]],\n",
    "\n",
    "        [[-4.12923850e-01, -3.98015639e-01, -3.82177900e-01, ...], \n",
    "        ...\n",
    "\n",
    "After the np.newaxis operation:\n",
    "•\tThe shape changes to (samples, channels, time_points, 1).\n",
    "•\tThis operation wraps each individual value (the scalar for each time point) into its own array (of size 1) and adds a new dimension.\n",
    "•\tNow, each time point for each channel/sample is a 1D array (each value in your array is now encapsulated as a single-element list or array).\n",
    "array([[[[ 3.24529244e-01],\n",
    "         [ 4.11996053e-01],\n",
    "         [ 4.91609174e-01],\n",
    "         ...],\n",
    " \n",
    "        [[ 1.84049422e-01],\n",
    "         [ 2.35332724e-01],\n",
    "         [ 2.83798373e-01],\n",
    "         ...],\n",
    "\n",
    "        [[-2.38773378e-01],\n",
    "         [-2.04526201e-01],\n",
    "         [-1.74333753e-01],\n",
    "         ...],\n",
    "\n",
    "        [[ 4.25627014e-01],\n",
    "         [ 4.73232880e-01],\n",
    "         [ 5.16544162e-01],\n",
    "         ...]]], \n",
    "       ...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 2 is out of bounds for array of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(X_augmented), np\u001b[38;5;241m.\u001b[39marray(y_augmented)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Apply augmentation on the whole dataset before splitting\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m X_aug, y_aug \u001b[38;5;241m=\u001b[39m \u001b[43maugment_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAugmented data shape: X=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_aug\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_aug\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m, in \u001b[0;36maugment_data\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     34\u001b[0m \t    \u001b[38;5;66;03m# The shifted data (X_shifted) is then appended to the augmented dataset (X_augmented), and the corresponding label (y[i]) is appended to y_augmented.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m# Shifting the data with np.roll can potentially disrupt the chronological order of the data, and this could negatively affect the ability of the model to learn meaningful patterns from the data, especially when detecting a time-sensitive event like the N170.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m shift \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m]:  \u001b[38;5;66;03m# Shift by 1 or 2 time steps\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m             X_shifted \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m             X_augmented\u001b[38;5;241m.\u001b[39mappend(X_shifted)\n\u001b[1;32m     39\u001b[0m             y_augmented\u001b[38;5;241m.\u001b[39mappend(y[i])\n",
      "File \u001b[0;32m/opt/miniconda3/envs/n170/lib/python3.10/site-packages/numpy/core/numeric.py:1211\u001b[0m, in \u001b[0;36mroll\u001b[0;34m(a, shift, axis)\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m roll(a\u001b[38;5;241m.\u001b[39mravel(), shift, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(a\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1211\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_axis_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_duplicate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m     broadcasted \u001b[38;5;241m=\u001b[39m broadcast(shift, axis)\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m broadcasted\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/n170/lib/python3.10/site-packages/numpy/core/numeric.py:1380\u001b[0m, in \u001b[0;36mnormalize_axis_tuple\u001b[0;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;66;03m# Going via an iterator directly is slower than via list comprehension.\u001b[39;00m\n\u001b[0;32m-> 1380\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([normalize_axis_index(ax, ndim, argname) \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis])\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(axis)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis):\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argname:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/n170/lib/python3.10/site-packages/numpy/core/numeric.py:1380\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;66;03m# Going via an iterator directly is slower than via list comprehension.\u001b[39;00m\n\u001b[0;32m-> 1380\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([\u001b[43mnormalize_axis_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis])\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(axis)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis):\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argname:\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 2 is out of bounds for array of dimension 2"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "def augment_data(X, y):\n",
    "    \n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "    \n",
    "    # Loop over each sample (trial or instance) in X\n",
    "    for i in range(X.shape[0]):\n",
    "        \n",
    "        # Original data\n",
    "        # For each sample, we first append the original data (X[i]) and the corresponding label (y[i]) to the X_augmented and y_augmented lists. \n",
    "        # This ensures that the original data is kept in the augmented dataset.\n",
    "        X_augmented.append(X[i])\n",
    "        y_augmented.append(y[i])\n",
    "\n",
    "        # Time-shifted data\n",
    "        # This block generates new samples by shifting the time steps of the data. \n",
    "        # The np.roll() function is used to shift the data along the time axis (axis=2). \n",
    "        # It shifts the entire time series by 1 or 2 time steps in both forward and backward directions (given by the shift values [-2, -1, 1, 2]).\n",
    "\t    # X_shifted = np.roll(X[i], shift, axis=2) shifts the time data in X[i] by shift units along the time axis.\n",
    "        '''\n",
    "        X[0] (shape: (3, 4)):\n",
    "        [[0.1, 0.2, 0.3, 0.4],\n",
    "         [0.5, 0.6, 0.7, 0.8],\n",
    "         [0.9, 1.0, 1.1, 1.2]]\n",
    "        \n",
    "        X_shifted = np.roll(X[0], 1, axis=2)\n",
    "        \n",
    "        X_shifted (shift = 1):\n",
    "        [[0.4, 0.1, 0.2, 0.3],\n",
    "         [0.8, 0.5, 0.6, 0.7],\n",
    "         [1.2, 0.9, 1.0, 1.1]]\n",
    "        '''\n",
    "\t    # The shifted data (X_shifted) is then appended to the augmented dataset (X_augmented), and the corresponding label (y[i]) is appended to y_augmented.\n",
    "        # Shifting the data with np.roll can potentially disrupt the chronological order of the data, and this could negatively affect the ability of the model to learn meaningful patterns from the data, especially when detecting a time-sensitive event like the N170.\n",
    "        for shift in [-2, -1, 1, 2]:  # Shift by 1 or 2 time steps\n",
    "            X_shifted = np.roll(X[i], shift, axis = 2)\n",
    "            X_augmented.append(X_shifted)\n",
    "            y_augmented.append(y[i])\n",
    "        \n",
    "        # Noise-injected data\n",
    "        # We add noise to the data to create new augmented samples that simulate real-world variations.\n",
    "\t    # noise = np.random.normal(0, 0.01, X[i].shape) generates random noise from a normal distribution with a mean of 0 and a standard deviation of 0.01. The noise has the same shape as the original data sample X[i].\n",
    "\t    # X_noisy = X[i] + noise adds the generated noise to the original sample.\n",
    "\t    # The noisy data (X_noisy) is then appended to X_augmented, and the corresponding label (y[i]) is appended to y_augmented.\n",
    "        noise = np.random.normal(0, 0.01, X[i].shape)\n",
    "        X_noisy = X[i] + noise\n",
    "        X_augmented.append(X_noisy)\n",
    "        y_augmented.append(y[i])\n",
    "\n",
    "    return np.array(X_augmented), np.array(y_augmented)\n",
    "\n",
    "# Apply augmentation on the whole dataset before splitting\n",
    "X_aug, y_aug = augment_data(X, y)\n",
    "\n",
    "print(f'Augmented data shape: X={X_aug.shape}, y={y_aug.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model Implementation using DeepConvNet\n",
    "def DeepConvNet(nb_classes, Chans = 4, Samples = 50, dropoutRate = 0.5):\n",
    "    \n",
    "    input_main = Input((Chans, Samples, 1))\n",
    "    \n",
    "    # Block 1\n",
    "    block1 = Conv2D(25, (1, 5), padding='same', use_bias=False)(input_main)\n",
    "    block1 = Conv2D(25, (Chans, 1), use_bias=False)(block1)\n",
    "    block1 = BatchNormalization()(block1)\n",
    "    block1 = Activation('elu')(block1)\n",
    "    block1 = MaxPooling2D((1, 2))(block1)\n",
    "    block1 = Dropout(0.2)(block1)\n",
    "    \n",
    "    # Block 2\n",
    "    block2 = Conv2D(50, (1, 5), padding='same', use_bias=False)(block1)\n",
    "    block2 = BatchNormalization()(block2)\n",
    "    block2 = Activation('elu')(block2)\n",
    "    block2 = MaxPooling2D((1, 2))(block2)\n",
    "    block2 = Dropout(0.3)(block2)\n",
    "    \n",
    "    # Block 3\n",
    "    block3 = Conv2D(100, (1, 5), padding='same', use_bias=False)(block2)\n",
    "    block3 = BatchNormalization()(block3)\n",
    "    block3 = Activation('elu')(block3)\n",
    "    block3 = MaxPooling2D((1, 2))(block3)\n",
    "    block3 = Dropout(0.4)(block3)\n",
    "    \n",
    "    # Block 4\n",
    "    block4 = Conv2D(200, (1, 5), padding='same', use_bias=False)(block3)\n",
    "    block4 = BatchNormalization()(block4)\n",
    "    block4 = Activation('elu')(block4)\n",
    "    block4 = MaxPooling2D((1, 2))(block4)\n",
    "    block4 = Dropout(0.5)(block4)\n",
    "    \n",
    "    # Flatten and Dense Layers\n",
    "    flatten = Flatten()(block4)\n",
    "    dense = Dense(nb_classes)(flatten)\n",
    "    softmax = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs = input_main, outputs = softmax)\n",
    "\n",
    "# Parameters for DeepConvNet\n",
    "Chans = X.shape[1]\n",
    "Samples = X.shape[2]\n",
    "nb_classes = 2  # Binary classification\n",
    "\n",
    "# Compile the model\n",
    "model = DeepConvNet(nb_classes = nb_classes, \n",
    "                    Chans = Chans, \n",
    "                    Samples = Samples, \n",
    "                    dropoutRate = 0.5)\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate=1e-3),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "# Adjust EarlyStopping and ReduceLROnPlateau\n",
    "early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                               patience=25, \n",
    "                               restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.5, \n",
    "                              patience=10,\n",
    "                              min_lr=1e-6, \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "epochs = 500\n",
    "batch_size = 16  # Keep batch size small for better gradient estimation\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_aug, \n",
    "                                                            y_aug, \n",
    "                                                            test_size = 0.2, \n",
    "                                                            random_state = 42, \n",
    "                                                            stratify = y_aug)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_val, \n",
    "                    y_train_val,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data = (X_test, y_test),\n",
    "                    callbacks = [early_stopping, reduce_lr],\n",
    "                    verbose = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and Visualization\n",
    "# Evaluate on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Visualize training history\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(cm, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues',\n",
    "            xticklabels=['Face', 'Car'],\n",
    "            yticklabels=['Face', 'Car'])\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['Face', 'Car']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/Users/owenanderson/Documents/NeurEx/Projects/P1_N170/Models/V2.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n170",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
