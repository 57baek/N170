{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa66RV0CcZk0"
   },
   "source": [
    "NeurEx Project 1: Binary Classification of Visual Stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovAi1VWecZk2"
   },
   "source": [
    "EEG Data Preprocessing Pipeline Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3NyKY2tcZk2"
   },
   "source": [
    "Step 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28753,
     "status": "ok",
     "timestamp": 1729958473564,
     "user": {
      "displayName": "Mark Shteyn",
      "userId": "03616534881215837864"
     },
     "user_tz": 240
    },
    "id": "0ppDgOWHcZk2",
    "outputId": "274c3d5a-8bff-4928-fac5-222e0e34aff4"
   },
   "outputs": [],
   "source": [
    "# This is a simple command to install the necessary toolboxes into our environment\n",
    "# !pip install mne autoreject numpy scikit-learn imbalanced-learn matplotlib\n",
    "# We will use a lot of \"toolboxes\" for our analysis\n",
    "# Think of a toolbox as a library of \"tool\", or functions that are premade and avaliable for us to use\n",
    "# This allows us to use specialized functions that optimally preprocess the data without the need for us to write our own functions\n",
    "# We still need to understand the functions we use, how they change the data, what the datatype they output are, and how we can work with them\n",
    "# Thankfully there is documentation (instructions) avaliable online that can tell us everything we need to know\n",
    "# Finally: USE CHATGPT!!!!!! We cannot emphasize enough how helpful chatgpt is for explaining concepts, debugging code, and helping you create optimized pipelines\n",
    "import os\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from autoreject import AutoReject\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "httAYYW0cZk2"
   },
   "source": [
    "Step 2: Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--Vqqb1CcZk3",
    "outputId": "dae6092a-8571-47b7-8797-5adfc6205445"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Define the root directory where the data is stored\n",
    "# This is the path to the directory that has your data\n",
    "bids_root = \"/Users/BAEK/Code/neurEx/project\"\n",
    "\n",
    "# This will iterate through each file in the folder that starts with sub, and then adds each subject to a list\n",
    "# Hint: os has a function called os.listdir that takes a folder path and returns a list with all of the directory contents\n",
    "subjects = [sub for sub in os.listdir(\"/Users/BAEK/Code/neurEx/project/N170 Raw Data BIDS-Compatible\") if sub.startswith(\"sub\")]\n",
    "# Create a variable that holds the current task\n",
    "# Hint: Our task is N170\n",
    "task = \"task-N170\"\n",
    "\n",
    "# Create a variable subject that will contain the first subject in the list subjects\n",
    "# This is the subject we will preprocess the data for\n",
    "# Hint: Remember indexing?\n",
    "subject = subjects[0]\n",
    "print(f'Processing subject: {subject}')\n",
    "\n",
    "# Define the path to the EEG data in EEGLAB format (.set file)\n",
    "# You will want to use os.path.join to join the bids_root, subject and filename\n",
    "# This creates the path that we will use to load in the data\n",
    "eeg_path = os.path.join(bids_root, subject, 'eeg', f'{subject}_{task}_eeg.set')\n",
    "\n",
    "# Read the raw EEG data using MNE's EEGLAB reader\n",
    "# Hint: MNE has a function called mne.io.read_raw_eeglab\n",
    "# You pass the path to the data and set the preload parameter to be true\n",
    "raw = mne.io.read_raw_eeglab(eeg_path, preload=True)\n",
    "''' \n",
    "# Define the root directory where the data is stored\n",
    "# This is the path to the directory that has your data\n",
    "bids_root = \"/Users/BAEK/Code/neurEx/project/tempData\"\n",
    "# This will iterate through each file in the folder that starts with sub, and then adds each subject to a list\n",
    "# Hint: os has a function called os.listdir that takes a folder path and returns a list with all of the directory contents\n",
    "subjects = [sub for sub in os.listdir(bids_root) if sub.startswith('sub')]\n",
    "# Create a variable that holds the current task\n",
    "# Hint: Our task is N170\n",
    "task = 'task-N170'\n",
    "# Create a variable subject that will contain the first subject in the list subjects\n",
    "# This is the subject we will preprocess the data for\n",
    "# Hint: Remember indexing?\n",
    "subject = subjects[0]\n",
    "print(f'Processing subject: {subject}')\n",
    "# Define the path to the EEG data in EEGLAB format (.set file)\n",
    "# You will want to use os.path.join to join the bids_root, subject and filename\n",
    "# This creates the path that we will use to load in the data\n",
    "eeg_path = os.path.join(bids_root, subject, 'eeg', f'{subject}_{task}_eeg.set')\n",
    "# Read the raw EEG data using MNE's EEGLAB reader\n",
    "# Hint: MNE has a function called mne.io.read_raw_eeglab\n",
    "# You pass the path to the data and set the preload parameter to be true\n",
    "raw = mne.io.read_raw_eeglab(eeg_path, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRfg6O9ccZk3"
   },
   "source": [
    "Step 3: Create a new event mapping for epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqPgj-OncZk3",
    "outputId": "e61cadb2-5eac-496d-d11d-971ab232dbdc"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of all integer event codes\n",
    "# Very simple, eg. 1:1, 43:43, 187:187\n",
    "# Allows us to use the \"events_from_annotations\" MNE function to create our events array\n",
    "annotations_mapping = {desc: int(desc) for desc in set(raw.annotations.description)}\n",
    "print(\"Annotations mapping:\", annotations_mapping)\n",
    "\n",
    "\n",
    "# Extract events using the annotations mapping\n",
    "# Events = an n events x 3 array\n",
    "# Column 1 = the sample numbers that represent the beginning of the epoch\n",
    "# Column 2 = all 0s\n",
    "# Column 3 = the event type (face, car, etc)\n",
    "events, _ = mne.events_from_annotations(raw, event_id=annotations_mapping)\n",
    "\n",
    "\n",
    "# Create a mapping from original event codes to condition labels\n",
    "# Each number from 1-202 has an associated event\n",
    "# Ex: 2 = face, 45 = car\n",
    "event_code_to_condition = {}\n",
    "\n",
    "# Map \"1-40\" to \"Stimulus - faces\"\n",
    "for code in range(1, 41):\n",
    "    event_code_to_condition[code] = 'Stimulus/Face'\n",
    "# Map \"41-80\" to \"Stimulus - cars\"\n",
    "for code in range(41, 81):\n",
    "    event_code_to_condition[code] = 'Stimulus/Car'\n",
    "# Map \"101-140\" to \"Stimulus - scrambled faces\"\n",
    "for code in range(101, 141):\n",
    "    event_code_to_condition[code] = 'Stimulus/ScrambledFace'\n",
    "# Map \"141-180\" to \"Stimulus - scrambled cars\"\n",
    "for code in range(141, 181):\n",
    "    event_code_to_condition[code] = 'Stimulus/ScrambledCar'\n",
    "\n",
    "# Map \"201\" to \"Response - correct\"\n",
    "event_code_to_condition[201] = 'Response/Correct'\n",
    "# Map \"202\" to \"Response - error\"\n",
    "event_code_to_condition[202] = 'Response/Error'\n",
    "\n",
    "# Assign new integer event IDs to each condition label\n",
    "condition_label_to_event_id = {\n",
    "    'Stimulus/Face': 1,\n",
    "    'Stimulus/Car': 2,\n",
    "    'Stimulus/ScrambledFace': 3,\n",
    "    'Stimulus/ScrambledCar': 4,\n",
    "    'Response/Correct': 5,\n",
    "    'Response/Error': 6\n",
    "}\n",
    "\n",
    "# Create a mapping from original event codes to new integer event IDs\n",
    "original_to_new_event_id = {}\n",
    "\n",
    "# Iterates through each event code (1-202)\n",
    "for code in event_code_to_condition:\n",
    "    # Extracts the condition label associated with the event code\n",
    "    condition_label = event_code_to_condition[code]\n",
    "    # Finds the new event code (1-6) that corresponds to the condition label\n",
    "    new_event_id = condition_label_to_event_id[condition_label]\n",
    "    # Creates new event code array where each event code (1-202) is mapped to its new event code (1-6)\n",
    "    original_to_new_event_id[code] = new_event_id\n",
    "\n",
    "# Apply the event ID mapping to the events array\n",
    "# Based on the original event codes (1-202), new event codes (1-6) are assigned to each event\n",
    "events[:, 2] = np.array([original_to_new_event_id.get(code, -1) for code in events[:, 2]])\n",
    "\n",
    "# Remove events with code -1 (events not in our mapping)\n",
    "events = events[events[:, 2] != -1]\n",
    "\n",
    "# Define the event_id mapping for epoching\n",
    "event_id = condition_label_to_event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvBeg-eTcZk3"
   },
   "source": [
    "Step 4: Create the montage (EEG channels used) and add it to the epoch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYhMBUnMcZk3",
    "outputId": "e0ac6816-aa98-41d4-90c0-b2ada5bbc2ee"
   },
   "outputs": [],
   "source": [
    "# Set channel types for EOG channels\n",
    "# EOG channels are different from EEG channels\n",
    "# EEG channels measures electrical activity in the brain\n",
    "# EOG channels measure electrical activity produced from your eye (not very important)\n",
    "# We need to distinguish them from the EEG channels\n",
    "eog_channels = ['HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
    "for ch in eog_channels:\n",
    "    if ch in raw.ch_names:\n",
    "        raw.set_channel_types({ch: 'eog'})\n",
    "\n",
    "# Apply montage directly, ignoring missing channels\n",
    "# This creates a digMontage object\n",
    "# A digMontage object contains each electrode and the positional data associated from the scalp\n",
    "# Hint: use mne.channels.make_standard_montage, the montage we are using is the standard 1020\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "\n",
    "# This sets the montage in the rawEEGLAB object\n",
    "# Hint: use the set_montage function\n",
    "raw.set_montage(montage, match_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Plb9xhVPcZk4",
    "outputId": "9309667a-445a-4be9-bf73-99551801a5ff"
   },
   "outputs": [],
   "source": [
    "# IGNORE THE DETAILS OF THIS CODE FOR NOW, IT IS JUST FOR VISUALIZATION PURPOSES\n",
    "tmin, tmax = -0.2, 0.6  # Time window from -200 ms to 600 ms\n",
    "\n",
    "epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n",
    "                    baseline=None, preload=True, detrend=1)\n",
    "\n",
    "# Compute the average (evoked) response for each condition\n",
    "evoked_face = epochs['Stimulus/Face'].average()\n",
    "evoked_Car = epochs['Stimulus/Car'].average()\n",
    "\n",
    "# Plot the averaged responses\n",
    "# Plotting the ERP for 'Stimulus/Face'\n",
    "evoked_face.plot(titles={'eeg': 'Face Stimulus ERP'}, spatial_colors=True)\n",
    "\n",
    "# Plotting the ERP for 'Stimulus/Object'\n",
    "evoked_Car.plot(titles={'eeg': 'Car Stimulus ERP'}, spatial_colors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAln6kbkcZk4"
   },
   "source": [
    "Step 5: Start Preprocessing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWZ5Am4_cZk4"
   },
   "source": [
    "Step 5a: Filter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LnyqdBZcZk4",
    "outputId": "47097fb5-dacb-4a9b-ed63-f775577b7d17"
   },
   "outputs": [],
   "source": [
    "# Bandpass filter the data between 0.1Hz and 30Hz using a \"firwin\" filter\n",
    "# Hint: mne.filter()\n",
    "raw.filter(0.1, 30., fir_design='firwin')\n",
    "\n",
    "# Apply notch filter at 60 Hz using a \"firwin\" filter\n",
    "# Hint: mne.notch_filter()\n",
    "raw.notch_filter(60., fir_design='firwin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRmlyDlhcZk4",
    "outputId": "f0e9a896-ecc9-4e62-f38a-79d4be37fa99"
   },
   "outputs": [],
   "source": [
    "# IGNORE THE DETAILS OF THIS CODE FOR NOW, IT IS JUST FOR VISUALIZATION PURPOSES\n",
    "tmin, tmax = -0.2, 0.6  # Time window from -200 ms to 600 ms\n",
    "\n",
    "epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n",
    "                    baseline=None, preload=True, detrend=1)\n",
    "\n",
    "# Compute the average (evoked) response for each condition\n",
    "evoked_face = epochs['Stimulus/Face'].average()\n",
    "evoked_Car = epochs['Stimulus/Car'].average()\n",
    "\n",
    "# Plot the averaged responses\n",
    "# Plotting the ERP for 'Stimulus/Face'\n",
    "evoked_face.plot(titles={'eeg': 'Face Stimulus ERP'}, spatial_colors=True)\n",
    "\n",
    "# Plotting the ERP for 'Stimulus/Object'\n",
    "evoked_Car.plot(titles={'eeg': 'Car Stimulus ERP'}, spatial_colors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T00nCuBTcZk4"
   },
   "source": [
    "Step 5b: Re-Reference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxRV-YYocZk4",
    "outputId": "6c4d9abd-1ff7-45e6-f597-a5105a0242b7"
   },
   "outputs": [],
   "source": [
    "# Re-reference to the average of all channels\n",
    "# Hint: mne.set_eeg_reference()\n",
    "raw.set_eeg_reference(ref_channels='average')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iu8hEcircZk4",
    "outputId": "63e8942e-345e-4b26-9f44-ce809e767e9a"
   },
   "outputs": [],
   "source": [
    "# IGNORE THE DETAILS OF THIS CODE FOR NOW, IT IS JUST FOR VISUALIZATION PURPOSES\n",
    "tmin, tmax = -0.2, 0.6  # Time window from -200 ms to 600 ms\n",
    "\n",
    "epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n",
    "                    baseline=None, preload=True, detrend=1)\n",
    "\n",
    "# Compute the average (evoked) response for each condition\n",
    "evoked_face = epochs['Stimulus/Face'].average()\n",
    "evoked_Car = epochs['Stimulus/Car'].average()\n",
    "\n",
    "# Plot the averaged responses\n",
    "# Plotting the ERP for 'Stimulus/Face'\n",
    "evoked_face.plot(titles={'eeg': 'Face Stimulus ERP'}, spatial_colors=True)\n",
    "\n",
    "# Plotting the ERP for 'Stimulus/Object'\n",
    "evoked_Car.plot(titles={'eeg': 'Car Stimulus ERP'}, spatial_colors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkjeA0BgcZk4"
   },
   "source": [
    "Step 5c: Apply ICA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCjHsqCXcZk4",
    "outputId": "7077ed44-98ae-4793-ac46-8401410b9dfa"
   },
   "outputs": [],
   "source": [
    "# Apply ICA to remove EOG (eye movement) artifacts\n",
    "# Eye movements such as blinks create distortions in our data called \"artifacts\"\n",
    "# These distortions can mask physiological data we are trying to extract\n",
    "# Lets remove them!\n",
    "# Hint: Use the ICA module from mne.preprocessing\n",
    "# number of components = 15\n",
    "# method = 'fastica'\n",
    "# random_state = 97\n",
    "# max_iter = 'auto'\n",
    "ica = ICA(n_components = 15, method = 'fastica', random_state = 97, max_iter = 'auto')\n",
    "# Apply the ica to the raw data\n",
    "# Hint: use ICA's fit method\n",
    "ica.fit(raw)\n",
    "\n",
    "# Find ICA components correlated with EOG artifacts\n",
    "# This identifies data points that are most likely associated with EOG artifacts and adds them to our ICA object\n",
    "# Hint: Use ica.find_bads_eog and the eog_channels object that we created earlier\n",
    "eog_indices, eog_scores = ica.find_bads_eog(raw, ch_name = eog_channels)\n",
    "# Exclude the found EOG artifacts\n",
    "ica.exclude = eog_indices\n",
    "\n",
    "# Apply the ICA solution to raw data to exclude the artifacts\n",
    "# Hint: Use ica.apply\n",
    "raw_corrected = ica.apply(raw.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXKHpfNicZk4",
    "outputId": "e4e9a476-3191-473b-d6cc-0dc57839fd7e"
   },
   "outputs": [],
   "source": [
    "# IGNORE THE DETAILS OF THIS CODE FOR NOW, IT IS JUST FOR VISUALIZATION PURPOSES\n",
    "tmin, tmax = -0.2, 0.6  # Time window from -200 ms to 600 ms\n",
    "\n",
    "epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n",
    "                    baseline=None, preload=True, detrend=1)\n",
    "\n",
    "# Compute the average (evoked) response for each condition\n",
    "evoked_face = epochs['Stimulus/Face'].average()\n",
    "evoked_Car = epochs['Stimulus/Car'].average()\n",
    "\n",
    "# Plot the averaged responses\n",
    "# Plotting the ERP for 'Stimulus/Face'\n",
    "evoked_face.plot(titles={'eeg': 'Face Stimulus ERP'}, spatial_colors=True)\n",
    "\n",
    "# Plotting the ERP for 'Stimulus/Object'\n",
    "evoked_Car.plot(titles={'eeg': 'Car Stimulus ERP'}, spatial_colors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqViaisPcZk4"
   },
   "source": [
    "Step 6: Define timerange for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CG_NtEvxcZk4"
   },
   "outputs": [],
   "source": [
    "# Define the time window (around the stimulus at t = 0) for each epoch\n",
    "# Hint: Our time window for each epoch is -200ms to 600ms\n",
    "tmin, tmax = -0.2, 0.6\n",
    "\n",
    "# We wont end up using the baseline correction just yet, but its function is to center all of the responses around 0 so they have the same starting point\n",
    "# This allows us to make better comparisons\n",
    "# Just define the interval for now, it is from -200 ms to 0 ms\n",
    "baseline = (tmin, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Nx9WWIPcZk4"
   },
   "source": [
    "Step 7: Create the MNE epochs object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzQol__GcZk4",
    "outputId": "0f3e9191-55b7-43bd-c110-332c3498301f"
   },
   "outputs": [],
   "source": [
    "# Create an MNE epochs object!\n",
    "# This object contains the preprocessed EEG data seperated into each epoch\n",
    "# .average() can be called on this object to average each epoch and obtain the evoked response\n",
    "# This can be achieved with the mne.Epochs method\n",
    "# You have created most of the parameters (use the API to determine what to enter)\n",
    "# Parameters that we have not created (include these last):\n",
    "# baseline=None, preload=True, detrend=1\n",
    "epochs = mne.Epochs(\n",
    "    raw=raw_corrected,       # Use the corrected raw data after ICA\n",
    "    events=events,           # The events array created from annotations\n",
    "    event_id=event_id,       # The dictionary mapping events to labels\n",
    "    tmin=tmin,               # Start of the time window (-0.2 seconds)\n",
    "    tmax=tmax,               # End of the time window (0.6 seconds)\n",
    "    baseline=baseline,       # Baseline interval from -0.2 to 0 seconds\n",
    "    preload=True,            # Preload data for faster access\n",
    "    detrend=1                # Linear detrending to remove DC offset\n",
    ")\n",
    "\n",
    "# Congradulations, you have successfully preprocessed and epoched EEG data for data analysis or deep learning purposes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qU_MYCGncZk4"
   },
   "source": [
    "Haha you thought we were done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4lDLWExcZk4"
   },
   "source": [
    "Step 8: Reject bad epochs (due to movement artifacts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlPpbNADcZk4"
   },
   "source": [
    "Movement artifacts are like EOG artifacts, except they are caused by bodily movement, such as shaking your head, or moving aronud in your seat during recording. Epochs with movement corrupted data need to be removed so that they do not hinder analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdP_VVpMcZk5"
   },
   "outputs": [],
   "source": [
    "# Thankfully there is a toolbox that can be used to auto reject bad epochs with 2 lines of code :)\n",
    "# Apply Autoreject to automatically reject bad epochs\n",
    "# Create the AutoReject object: AutoReject()\n",
    "ar = AutoReject()\n",
    "\n",
    "# Apply the auto rejection to the epochs object we created\n",
    "# This can be achieved with SKLearns fit_transform function\n",
    "# Make sure return_log=True\n",
    "epochs_clean, reject_log = ar.fit_transform(epochs, return_log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn5blK-WcZk5"
   },
   "source": [
    "Step 9: Finally we will apply the baseline correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNk-llV-cZk5"
   },
   "outputs": [],
   "source": [
    "# Apply baseline correction after artifact rejection\n",
    "# Hint: use the mne.apply_baseline function with the baseline we created earlier\n",
    "epochs_clean.apply_baseline(baseline=baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubOVbDYpcZk5"
   },
   "source": [
    "Step 10: Lets visualize the preprocessed data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFqshgPGcZk5"
   },
   "outputs": [],
   "source": [
    "# Simply compute the average (evoked) response for each condition\n",
    "# Hint use the .average() function on the face and car stimulus data from epochs_clean\n",
    "evoked_face = epochs_clean['Stimulus/Face'].average()\n",
    "evoked_Car = epochs_clean['Stimulus/Car'].average()\n",
    "\n",
    "# Plotting the ERP for Face\n",
    "# Use mne's plot function with the parameters:\n",
    "# titles={'eeg': 'Face Stimulus ERP'}, spatial_colors=True\n",
    "evoked_face.plot(titles={'eeg': 'Face Stimulus ERP'}, spatial_colors=True)\n",
    "# plt.savefig('average_erp_face.png') # Optional: Save the plot!\n",
    "\n",
    "# Plotting the ERP for Object\n",
    "# Use mne's plot function with the parameters:\n",
    "# titles={'eeg': 'Car Stimulus ERP'}, spatial_colors=True\n",
    "evoked_Car.plot(titles={'eeg': 'Car Stimulus ERP'}, spatial_colors=True)\n",
    "# plt.savefig('average_erp_car.png') # Optional: Save the plot!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJvkSzT3cZk5"
   },
   "source": [
    "Now you actually are done, in reality we would run this preprocessing script in batch style and append all of the data for each class into one data structure that we would further process to optimize it for deep learning classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WNBECpYcZk5"
   },
   "source": [
    "Tune in next week to delve into how we can analyze this data with deep learning!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "neur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
